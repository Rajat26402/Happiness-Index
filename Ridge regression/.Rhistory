#install.packages("lava")
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
#cleaning dataset - omiting NA values
# train<-na.omit(train)
# nrow(train)
# test<-na.omit(test)
# nrow(test)
# Model Building :Lasso Regression
# set.seed(123)
# control = trainControl(method ="cv", number = 5)
# Grid_reg = expand.grid(alpha = 1, lambda = seq(0.001,
#                                                0.1, by = 0.0002))
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = train[ , -c(1,2,3,13)]
y = train$Happiness.Score
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean=mean(Ridge_model$resample$RMSE)
# accuracy
acc = 100-(mean*100)
print(paste("Accuracy=",acc,"%"))
#R2
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
#ridge model new - after imputing NA values with median values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lamda=cv_model$lambda.min
best_lamda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
#ridge model new - after imputing NA values with median values
#install.packages("cowplot")
#install.packages("caret")
#install.packages("xgboost")
#install.packages("lava")
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lamda=cv_model$lambda.min
best_lamda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
setwd("D:/VIT/5th Semester/FDA/Review 3/Ridge Regression")
#ridge model new - after imputing NA values with median values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lamda=cv_model$lambda.min
best_lamda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
#ridge model new - after imputing NA values with median values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lambda = cv_model$lambda.min
best_lambda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
# Plot
plot(Ridge_model, main="Ridge Regression")
#ridge model old - after omiting NA values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("C:/Users/Rajat/Downloads/2016_excel.csv")
#ridge model old - after omiting NA values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_withNA.csv")
test = read.csv("2017_withNA.csv")
#cleaning dataset - omiting NA values
train<-na.omit(train)
nrow(train)
test<-na.omit(test)
nrow(test)
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lambda=cv_model$lambda.min
best_lambda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
# Plot
plot(Ridge_model, main="Ridge Regression")
#ridge model new - after imputing NA values with median values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lambda=cv_model$lambda.min
best_lambda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
# mean validation score
mean=mean(Ridge_model$resample$RMSE)
acc=mean*100
# Plot
plot(Ridge_model, main="Ridge Regression")
acc
#R2 Plot
rwithNA <- c(0.99,0.99,0.99,0.99)
rwithoutNA <- c(0.97,0.97,0.98,0.97)
model <- c("PLS","Lasso","Ridge","MLR")
# creating plot using the above data
ggplot(acc1, aes(model, rwithNA)) +
geom_bar(stat="identity",fill="yellow") +
labs(title="R2 between each model with NA")
ggplot(acc2, aes(model, rwithoutNA)) +
geom_bar(stat="identity",fill="green") +
labs(title="R2 between each model without NA")
#ridge model new - after imputing NA values with median values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lambda=cv_model$lambda.min
best_lambda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
#Accuracy
error=(sum(abs(y_predicted-y)))/sum(y)*100
accuracy=100-error
print(accuracy)
# Plot
plot(Ridge_model, main="Ridge Regression")
#ridge model old - after omiting NA values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("C:/Users/Rajat/Downloads/2016_excel.csv")
#ridge model old - after omiting NA values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_withNA.csv")
test = read.csv("2017_withNA.csv")
#cleaning dataset - omiting NA values
train<-na.omit(train)
nrow(train)
test<-na.omit(test)
nrow(test)
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lamda=cv_model$lambda.min
best_lamda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
#Accuracy
error=(sum(abs(y_predicted-y)))/sum(y)*100
accuracy=100-error
print(accuracy)
# Plot
plot(Ridge_model, main="Ridge Regression")
# Graph - Accuracy and R2 between each model
# With NA (Omitting NA)
# Without NA (Imputing NA)
#install.packages("ggplot2")
library(ggplot2)
accuracywithNA <- c(93.94,96.14,98.58,99.99)
accuracywithoutNA <- c(93.20,97.58,99.43,98.07)
model <- c("PLS","Lasso","Ridge","MLR")
# creating plot using the above data
ggplot(acc1, aes(model, accuracywithNA)) +
geom_bar(stat="identity",fill="yellow") +
labs(title="Accuracy between each model with NA")
ggplot(acc2, aes(model, accuracywithoutNA)) +
geom_bar(stat="identity",fill="green") +
labs(title="Accuracy between each model without NA")
#ridge model new - after imputing NA values with median values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_new.csv")
test = read.csv("2017_new.csv")
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lambda=cv_model$lambda.min
best_lambda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
#Accuracy
error=(sum(abs(y_predicted-y)))/sum(y)*100
accuracy=100-error
print(accuracy)
# Plot
plot(Ridge_model, main="Ridge Regression")
#ridge model old - after omiting NA values
# load packages
library(data.table) # used for reading and manipulation of data
library(dplyr)	 # used for data manipulation and joining
library(glmnet)	 # used for regression
library(ggplot2) # used for ploting
library(caret)	 # used for modeling
library(xgboost) # used for building XGBoost model
library(e1071)	 # used for skewness
library(cowplot) # used for combining multiple plots
# Loading datasets
train = read.csv("2016_withNA.csv")
test = read.csv("2017_withNA.csv")
#cleaning dataset - omiting NA values
train<-na.omit(train)
nrow(train)
test<-na.omit(test)
nrow(test)
# Model Building : Ridge Regression
set.seed(123)
control = trainControl(method ="cv", number = 5)
Grid_reg = expand.grid(alpha = 0, lambda = seq(0.001, 0.1,
by = 0.0002))
x = data.matrix(train[ , c(5,6,7,8,9,10,11,12,13)])
y = train$Happiness.Score
model=glmnet(x,y,alpha=0)
cv_model=cv.glmnet(x,y, alpha=0)
best_lamda=cv_model$lambda.min
best_lamda
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
# Training Ridge Regression model
Ridge_model = train(x,
y,
method = "glmnet",
trControl = control,
tuneGrid = Grid_reg
)
Ridge_model
# mean validation score
mean(Ridge_model$resample$RMSE)
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
#Accuracy
error=(sum(abs(y_predicted-y)))/sum(y)*100
accuracy=100-error
print(accuracy)
# Plot
plot(Ridge_model, main="Ridge Regression")
